{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this script we build line detector model using  Multilayer perceptron classifier in pyspark\n",
    "- BY: Abdelraouf Hawash \n",
    "- DATE: 23 / 12 / 2022"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/17 06:50:53 WARN Utils: Your hostname, Raouf-PC resolves to a loopback address: 127.0.1.1; using 192.168.1.100 instead (on interface wlp2s0)\n",
      "22/12/17 06:50:53 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/17 06:51:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier, MultilayerPerceptronClassificationModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### important attributes and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['QR','empty','horizontal','lef3','left2','lef1','center','right1','right2','right3']\n",
    "\n",
    "def preprocessing (img, dest_size = (20,20), dest_rang: int = 16):\n",
    "    '''\n",
    "    this function resize the image then makes pixels in a certain range\n",
    "    it takes about 0.00035 s\n",
    "    the input image should be in gray scale\n",
    "    '''\n",
    "    if len(img.shape) == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    out = (cv2.resize(img, dest_size) * (dest_rang/255)).astype('uint8')\n",
    "    return out.reshape( out.shape[0] * out.shape[1] )\n",
    "\n",
    "def show_processed_img (input, dest_size = (20,20), input_range: int = 16):\n",
    "    out = (input.reshape(dest_size) * (255/input_range)).astype('uint8')\n",
    "    cv2.imshow(\"source image\", out)\n",
    "    k = cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11 12 12 ... 12 12 12]\n",
      " [ 5  5  5 ...  8  9  9]\n",
      " [10 10 10 ...  8  8  7]\n",
      " ...\n",
      " [14 13 14 ...  7  8  7]\n",
      " [ 5  6  5 ... 10  8  8]\n",
      " [12 13 13 ...  9  7  7]]\n",
      "(4563, 400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/raouf/.local/lib/python3.10/site-packages/cv2/qt/plugins\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lef1' 'QR' 'empty' ... 'center' 'QR' 'QR']\n",
      "(4563,)\n",
      "[5 0 1 ... 6 0 0]\n",
      "(4563,)\n"
     ]
    }
   ],
   "source": [
    "X_data = np.load('./../data/X_data.npy')\n",
    "print(X_data)\n",
    "print(X_data.shape)\n",
    "show_processed_img(X_data[1])\n",
    "\n",
    "Y_data = np.load('./../data/y_data.npy')\n",
    "print(Y_data)\n",
    "print(Y_data.shape)\n",
    "\n",
    "Y_data = np.asarray([classes.index(i) for i in Y_data])\n",
    "print(Y_data)\n",
    "print(Y_data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Creating Spark dataframe from numpy matrix](https://stackoverflow.com/questions/45063591/creating-spark-dataframe-from-numpy-matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, DenseVector([5.0, 5.0, 5.0, 6.0, 6.0, 7.0, 7.0, 11.0, 11.0, 13.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 12.0, 5.0, 6.0, 6.0, 5.0, 6.0, 7.0, 7.0, 10.0, 6.0, 3.0, 4.0, 4.0, 4.0, 7.0, 3.0, 3.0, 3.0, 14.0, 12.0, 12.0, 5.0, 6.0, 6.0, 6.0, 6.0, 7.0, 6.0, 11.0, 6.0, 11.0, 14.0, 14.0, 3.0, 14.0, 14.0, 14.0, 13.0, 14.0, 12.0, 12.0, 5.0, 5.0, 6.0, 5.0, 6.0, 7.0, 7.0, 10.0, 6.0, 2.0, 13.0, 13.0, 13.0, 5.0, 13.0, 3.0, 14.0, 14.0, 12.0, 12.0, 5.0, 5.0, 5.0, 5.0, 6.0, 7.0, 7.0, 10.0, 6.0, 2.0, 12.0, 4.0, 2.0, 4.0, 13.0, 3.0, 14.0, 14.0, 12.0, 11.0, 5.0, 5.0, 6.0, 6.0, 6.0, 7.0, 6.0, 10.0, 6.0, 11.0, 12.0, 13.0, 13.0, 13.0, 14.0, 14.0, 14.0, 14.0, 12.0, 11.0, 5.0, 5.0, 5.0, 5.0, 6.0, 7.0, 6.0, 10.0, 1.0, 1.0, 2.0, 5.0, 3.0, 4.0, 3.0, 3.0, 3.0, 14.0, 12.0, 12.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 9.0, 5.0, 10.0, 12.0, 3.0, 3.0, 14.0, 14.0, 14.0, 3.0, 14.0, 5.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 9.0, 5.0, 10.0, 11.0, 13.0, 3.0, 14.0, 5.0, 14.0, 14.0, 14.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 9.0, 10.0, 1.0, 11.0, 4.0, 2.0, 3.0, 13.0, 2.0, 2.0, 14.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 9.0, 5.0, 10.0, 1.0, 4.0, 2.0, 13.0, 2.0, 13.0, 2.0, 13.0, 5.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 9.0, 10.0, 10.0, 1.0, 10.0, 12.0, 11.0, 11.0, 11.0, 12.0, 12.0, 3.0, 2.0, 4.0, 5.0, 5.0, 5.0, 5.0, 7.0, 5.0, 9.0, 1.0, 1.0, 10.0, 3.0, 11.0, 11.0, 2.0, 2.0, 2.0, 11.0, 9.0, 9.0, 4.0, 5.0, 5.0, 6.0, 5.0, 6.0, 6.0, 9.0, 5.0, 10.0, 1.0, 3.0, 1.0, 2.0, 9.0, 7.0, 11.0, 11.0, 9.0, 9.0, 5.0, 5.0, 5.0, 5.0, 6.0, 7.0, 5.0, 9.0, 9.0, 10.0, 1.0, 1.0, 10.0, 10.0, 8.0, 2.0, 11.0, 11.0, 9.0, 9.0, 4.0, 5.0, 5.0, 5.0, 6.0, 7.0, 6.0, 9.0, 1.0, 1.0, 10.0, 10.0, 10.0, 10.0, 7.0, 1.0, 11.0, 11.0, 9.0, 9.0, 5.0, 5.0, 5.0, 5.0, 6.0, 7.0, 6.0, 10.0, 1.0, 10.0, 1.0, 4.0, 5.0, 3.0, 7.0, 11.0, 11.0, 11.0, 9.0, 9.0, 5.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 9.0, 9.0, 9.0, 10.0, 9.0, 10.0, 10.0, 10.0, 11.0, 11.0, 11.0, 8.0, 8.0, 5.0, 5.0, 5.0, 5.0, 6.0, 7.0, 6.0, 9.0, 9.0, 9.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 11.0, 11.0, 9.0, 8.0, 5.0, 6.0, 6.0, 6.0, 6.0, 7.0, 6.0, 6.0, 7.0, 7.0, 6.0, 7.0, 7.0, 9.0, 10.0, 10.0, 10.0, 8.0, 9.0, 9.0]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/17 06:51:50 WARN TaskSetManager: Stage 0 contains a task of very large size (3619 KiB). The maximum recommended task size is 1000 KiB.\n",
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    5|[11.0,12.0,12.0,1...|\n",
      "|    0|[5.0,5.0,5.0,6.0,...|\n",
      "|    1|[10.0,10.0,10.0,1...|\n",
      "|    0|[11.0,11.0,11.0,1...|\n",
      "|    6|[12.0,12.0,12.0,1...|\n",
      "|    0|[11.0,11.0,11.0,1...|\n",
      "|    1|[10.0,10.0,10.0,1...|\n",
      "|    4|[13.0,13.0,13.0,1...|\n",
      "|    1|[8.0,8.0,7.0,8.0,...|\n",
      "|    0|[6.0,6.0,6.0,6.0,...|\n",
      "|    1|[8.0,8.0,8.0,8.0,...|\n",
      "|    2|[12.0,13.0,12.0,1...|\n",
      "|    2|[14.0,14.0,14.0,1...|\n",
      "|    8|[14.0,14.0,14.0,1...|\n",
      "|    4|[10.0,7.0,4.0,4.0...|\n",
      "|    4|[2.0,2.0,2.0,2.0,...|\n",
      "|    1|[7.0,7.0,7.0,8.0,...|\n",
      "|    1|[11.0,11.0,11.0,1...|\n",
      "|    4|[11.0,11.0,12.0,1...|\n",
      "|    5|[12.0,12.0,12.0,1...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data = [(int(y), Vectors.dense(x)) for (x,y) in zip(X_data,Y_data)]\n",
    "print(data[1])\n",
    "\n",
    "df = spark.createDataFrame(data, schema=['label', 'features'])\n",
    "df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.8, 0.2], 1234)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building and training model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Multilayer perceptron classifier](https://spark.apache.org/docs/3.3.1/ml-classification-regression.html#multilayer-perceptron-classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify layers for the neural network:\n",
    "# input layer of size 400 (features), two intermediate of size 5 and 4\n",
    "# and output of size 10 (classes)\n",
    "layers = [400, 200, 200, 200, 200 , 10]\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=2000, layers=layers, blockSize=128, seed=1234)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model >>> (70 mint )\n",
    "model = trainer.fit(train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/16 22:48:06 WARN DAGScheduler: Broadcasting large task binary with size 1655.0 KiB\n",
      "22/12/16 22:48:06 WARN TaskSetManager: Stage 2170 contains a task of very large size (3619 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2170:============================>                           (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.9022801302931596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result = model.transform(test)\n",
    "predictionAndLabels = result.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/16 22:39:58 WARN TaskSetManager: Stage 2161 contains a task of very large size (1621 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model.save(\"model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading learned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "MLPC_model = MultilayerPerceptronClassificationModel.load('model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using model and calculating the time of processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction =  QR\n",
      "time of processing =  0.027230189  s\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"./../raw_data/QR/0.jpg\",0) # you must load it as gray scale image\n",
    "e1 = cv2.getTickCount()\n",
    "features = preprocessing(img)\n",
    "prediction = MLPC_model.predict(Vectors.dense(features))\n",
    "e2 = cv2.getTickCount()\n",
    "time = (e2 - e1)/ cv2.getTickFrequency()\n",
    "\n",
    "print(\"prediction = \" , classes[round(prediction)])\n",
    "print(\"time of processing = \",time,\" s\") # time of processing =  0.002  s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using live from camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "center\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "lef1\n",
      "horizontal\n",
      "empty\n",
      "horizontal\n",
      "horizontal\n",
      "center\n",
      "horizontal\n",
      "center\n",
      "center\n",
      "horizontal\n",
      "horizontal\n",
      "horizontal\n",
      "empty\n",
      "empty\n",
      "horizontal\n",
      "horizontal\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "lef1\n",
      "horizontal\n",
      "horizontal\n",
      "lef1\n",
      "empty\n",
      "horizontal\n",
      "lef1\n",
      "horizontal\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "horizontal\n",
      "horizontal\n",
      "lef3\n",
      "lef3\n",
      "lef1\n",
      "lef1\n",
      "left2\n",
      "lef1\n",
      "lef1\n",
      "lef3\n",
      "lef3\n",
      "center\n",
      "horizontal\n",
      "horizontal\n",
      "horizontal\n",
      "horizontal\n",
      "horizontal\n",
      "horizontal\n",
      "right1\n",
      "horizontal\n",
      "right2\n",
      "right2\n",
      "horizontal\n",
      "empty\n",
      "empty\n",
      "empty\n",
      "horizontal\n",
      "horizontal\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "center\n",
      "horizontal\n",
      "center\n",
      "lef1\n",
      "center\n",
      "lef1\n",
      "lef1\n",
      "center\n",
      "horizontal\n",
      "horizontal\n",
      "lef1\n",
      "empty\n",
      "empty\n",
      "lef1\n",
      "lef1\n",
      "lef1\n",
      "lef1\n",
      "left2\n",
      "lef1\n",
      "lef1\n",
      "horizontal\n",
      "right1\n",
      "QR\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "center\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "center\n",
      "right1\n",
      "right1\n",
      "center\n",
      "right1\n",
      "lef1\n",
      "lef1\n",
      "center\n",
      "right1\n",
      "center\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "lef1\n",
      "center\n",
      "right1\n",
      "center\n",
      "right1\n",
      "right1\n",
      "center\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "QR\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "center\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "center\n",
      "center\n",
      "lef1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "horizontal\n",
      "horizontal\n",
      "right1\n",
      "horizontal\n",
      "right1\n",
      "right1\n",
      "center\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "center\n",
      "center\n",
      "center\n",
      "right1\n",
      "center\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "center\n",
      "center\n",
      "center\n",
      "center\n",
      "center\n",
      "center\n",
      "center\n",
      "center\n",
      "center\n",
      "center\n",
      "center\n",
      "center\n",
      "lef1\n",
      "center\n",
      "center\n",
      "center\n",
      "horizontal\n",
      "horizontal\n",
      "center\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "center\n",
      "center\n",
      "horizontal\n",
      "center\n",
      "center\n",
      "center\n",
      "center\n",
      "center\n",
      "center\n",
      "center\n",
      "center\n",
      "horizontal\n",
      "horizontal\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n",
      "right1\n"
     ]
    }
   ],
   "source": [
    "camera = cv2.VideoCapture(0)\n",
    "while (camera.isOpened):\n",
    "    ret, frame = camera.read()\n",
    "    cv2.imshow(\"camera\", frame)\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    features = preprocessing(img)\n",
    "    prediction = MLPC_model.predict(Vectors.dense(features))\n",
    "    \n",
    "    print( classes[round(prediction)] )\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "camera.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
